{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMy10e5hUxCrkHgkmvhas9S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namankathuria21/REGRESSION/blob/main/REGRESSION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression Assignment\n",
        "\n",
        "Q1. What is Simple Linear Regression?\n",
        "\n",
        "Simple Linear Regression is a statistical method used to model the relationship between one independent variable (X) and one dependent variable (Y).\n",
        "\n",
        "Equation: Y = mX + c\n",
        "\n",
        "Purpose: To predict Y using X and determine how X influences Y.\n",
        "\n",
        "Q2. What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "Linearity: Relationship between X and Y is linear.\n",
        "\n",
        "Independence: Observations are independent.\n",
        "\n",
        "Homoscedasticity: Constant variance of residuals.\n",
        "\n",
        "Normality: Residuals follow a normal distribution.\n",
        "\n",
        "No strong outliers.\n",
        "\n",
        "Q3. What does the coefficient m represent in the equation Y = mX + c?\n",
        "\n",
        "The slope (m) represents the rate of change in Y for a one-unit change in X.\n",
        "\n",
        "Example: If m = 2, then each increase of 1 unit in X increases Y by 2.\n",
        "\n",
        "Q4. What does the intercept c represent in the equation Y = mX + c?\n",
        "\n",
        "The intercept (c) is the expected value of Y when X = 0. It provides the baseline starting point of the regression line.\n",
        "\n",
        "Q5. How do we calculate the slope m in Simple Linear Regression?\n",
        "ğ‘š\n",
        "=\n",
        "âˆ‘\n",
        "(\n",
        "ğ‘‹\n",
        "ğ‘–\n",
        "âˆ’\n",
        "ğ‘‹\n",
        "Ë‰\n",
        ")\n",
        "(\n",
        "ğ‘Œ\n",
        "ğ‘–\n",
        "âˆ’\n",
        "ğ‘Œ\n",
        "Ë‰\n",
        ")\n",
        "âˆ‘\n",
        "(\n",
        "ğ‘‹\n",
        "ğ‘–\n",
        "âˆ’\n",
        "ğ‘‹\n",
        "Ë‰\n",
        ")\n",
        "2\n",
        "m=\n",
        "âˆ‘(X\n",
        "i\n",
        "\tâ€‹\n",
        "\n",
        "âˆ’\n",
        "X\n",
        "Ë‰\n",
        ")\n",
        "2\n",
        "âˆ‘(X\n",
        "i\n",
        "\tâ€‹\n",
        "\n",
        "âˆ’\n",
        "X\n",
        "Ë‰\n",
        ")(Y\n",
        "i\n",
        "\tâ€‹\n",
        "\n",
        "âˆ’\n",
        "Y\n",
        "Ë‰\n",
        ")\n",
        "\tâ€‹\n",
        "\n",
        "\n",
        "This formula minimizes the squared errors between predicted and actual Y values.\n",
        "\n",
        "Q6. What is the purpose of the least squares method in Simple Linear Regression?\n",
        "\n",
        "Least Squares minimizes the sum of squared differences between observed and predicted Y values, ensuring the best-fitting regression line.\n",
        "\n",
        "Q7. How is the coefficient of determination (RÂ²) interpreted in Simple Linear Regression?\n",
        "\n",
        "RÂ² measures how much variance in Y is explained by X.\n",
        "\n",
        "Range: 0 to 1.\n",
        "\n",
        "Example: RÂ² = 0.80 â†’ 80% of variation in Y is explained by X.\n",
        "\n",
        "Q8. What is Multiple Linear Regression?\n",
        "\n",
        "Multiple Linear Regression models the relationship between one dependent variable and multiple independent variables.\n",
        "\n",
        "Equation: Y = bâ‚€ + bâ‚Xâ‚ + bâ‚‚Xâ‚‚ + ... + bâ‚™Xâ‚™ + Îµ\n",
        "\n",
        "Q9. What is the main difference between Simple and Multiple Linear Regression?\n",
        "\n",
        "Simple Linear Regression â†’ One predictor (X).\n",
        "\n",
        "Multiple Linear Regression â†’ Two or more predictors (Xâ‚, Xâ‚‚, â€¦).\n",
        "\n",
        "Q10. What are the key assumptions of Multiple Linear Regression?\n",
        "\n",
        "Linearity between predictors and outcome.\n",
        "\n",
        "Independence of errors.\n",
        "\n",
        "Homoscedasticity.\n",
        "\n",
        "Normal distribution of residuals.\n",
        "\n",
        "No multicollinearity (independent variables shouldnâ€™t be highly correlated).\n",
        "\n",
        "Q11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
        "\n",
        "Heteroscedasticity: Residuals have unequal variance.\n",
        "\n",
        "Effect: Leads to inefficient estimates, biased standard errors, and invalid hypothesis tests.\n",
        "\n",
        "Q12. How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "\n",
        "Remove highly correlated variables.\n",
        "\n",
        "Use Principal Component Analysis (PCA).\n",
        "\n",
        "Use Ridge or Lasso Regression (regularization).\n",
        "\n",
        "Q13. What are some common techniques for transforming categorical variables for use in regression models?\n",
        "\n",
        "One-Hot Encoding\n",
        "\n",
        "Label Encoding\n",
        "\n",
        "Dummy Variables\n",
        "\n",
        "Target Encoding\n",
        "\n",
        "Q14. What is the role of interaction terms in Multiple Linear Regression?\n",
        "\n",
        "Interaction terms capture the combined effect of two variables.\n",
        "Example: Income Ã— Education may explain salary better than individual effects.\n",
        "\n",
        "Q15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
        "\n",
        "Simple: Intercept = Expected Y when X = 0.\n",
        "\n",
        "Multiple: Intercept = Expected Y when all predictors = 0 (may not always be meaningful).\n",
        "\n",
        "Q16. What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "\n",
        "Slope shows how much Y changes with a one-unit change in X (holding other variables constant in multiple regression).\n",
        "\n",
        "Q17. How does the intercept in a regression model provide context for the relationship between variables?\n",
        "\n",
        "It provides a baseline value of Y when predictors are absent (X = 0).\n",
        "\n",
        "Q18. What are the limitations of using RÂ² as a sole measure of model performance?\n",
        "\n",
        "High RÂ² doesnâ€™t guarantee causation.\n",
        "\n",
        "Adding more predictors always increases RÂ² (can be misleading).\n",
        "\n",
        "Doesnâ€™t measure overfitting.\n",
        "\n",
        "Q19. How would you interpret a large standard error for a regression coefficient?\n",
        "\n",
        "Large SE â†’ Coefficient is unstable and unreliable.\n",
        "\n",
        "Suggests multicollinearity or insufficient data.\n",
        "\n",
        "Q20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "\n",
        "Identified when residuals form a funnel shape in scatter plots.\n",
        "\n",
        "Important to fix â†’ prevents invalid p-values and confidence intervals.\n",
        "\n",
        "Q21. What does it mean if a Multiple Linear Regression model has a high RÂ² but low adjusted RÂ²?\n",
        "\n",
        "High RÂ²: Many variables explain variance.\n",
        "\n",
        "Low Adjusted RÂ²: Extra predictors are not actually useful (overfitting).\n",
        "\n",
        "Q22. Why is it important to scale variables in Multiple Linear Regression?\n",
        "\n",
        "Ensures comparability of coefficients.\n",
        "\n",
        "Improves numerical stability.\n",
        "\n",
        "Essential for models with regularization (Ridge/Lasso).\n",
        "\n",
        "Q23. What is polynomial regression?\n",
        "\n",
        "Polynomial Regression models non-linear relationships by including polynomial terms of predictors.\n",
        "\n",
        "Q24. How does polynomial regression differ from linear regression?\n",
        "\n",
        "Linear regression: Straight-line fit.\n",
        "\n",
        "Polynomial regression: Curved line fit using squared, cubic, etc. terms.\n",
        "\n",
        "Q25. When is polynomial regression used?\n",
        "\n",
        "When the relationship between variables is non-linear but can be approximated by a polynomial curve.\n",
        "\n",
        "Q26. What is the general equation for polynomial regression?\n",
        "ğ‘Œ\n",
        "=\n",
        "ğ‘\n",
        "0\n",
        "+\n",
        "ğ‘\n",
        "1\n",
        "ğ‘‹\n",
        "+\n",
        "ğ‘\n",
        "2\n",
        "ğ‘‹\n",
        "2\n",
        "+\n",
        "ğ‘\n",
        "3\n",
        "ğ‘‹\n",
        "3\n",
        "+\n",
        ".\n",
        ".\n",
        ".\n",
        "+\n",
        "ğ‘\n",
        "ğ‘›\n",
        "ğ‘‹\n",
        "ğ‘›\n",
        "+\n",
        "ğœ€\n",
        "Y=b\n",
        "0\n",
        "\tâ€‹\n",
        "\n",
        "+b\n",
        "1\n",
        "\tâ€‹\n",
        "\n",
        "X+b\n",
        "2\n",
        "\tâ€‹\n",
        "\n",
        "X\n",
        "2\n",
        "+b\n",
        "3\n",
        "\tâ€‹\n",
        "\n",
        "X\n",
        "3\n",
        "+...+b\n",
        "n\n",
        "\tâ€‹\n",
        "\n",
        "X\n",
        "n\n",
        "+Îµ\n",
        "Q27. Can polynomial regression be applied to multiple variables?\n",
        "\n",
        "Yes. Multivariate polynomial regression includes polynomial terms of multiple predictors.\n",
        "\n",
        "Q28. What are the limitations of polynomial regression?\n",
        "\n",
        "High degree â†’ overfitting.\n",
        "\n",
        "Sensitive to outliers.\n",
        "\n",
        "Hard to interpret.\n",
        "\n",
        "Q29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
        "\n",
        "Adjusted RÂ²\n",
        "\n",
        "Cross-validation\n",
        "\n",
        "AIC/BIC (Information Criteria)\n",
        "\n",
        "Residual analysis\n",
        "\n",
        "Q30. Why is visualization important in polynomial regression?\n",
        "\n",
        "Helps confirm non-linearity.\n",
        "\n",
        "Shows whether polynomial degree is appropriate.\n",
        "\n"
      ],
      "metadata": {
        "id": "Gm80lV294KZx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVgAUNTq4GEp"
      },
      "outputs": [],
      "source": [
        "#Q31. How is polynomial regression implemented in Python?\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Sample data\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1,1)\n",
        "y = np.array([2, 5, 10, 17, 26])\n",
        "\n",
        "# Polynomial transformation\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Fit regression\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_poly)\n",
        "\n",
        "plt.scatter(X, y, color=\"blue\")\n",
        "plt.plot(X, y_pred, color=\"red\")\n",
        "plt.title(\"Polynomial Regression\")\n",
        "plt.show()"
      ]
    }
  ]
}